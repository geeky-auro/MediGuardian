{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geeky-auro/MediGuardian/blob/main/MediGuardian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3mzBf2fB6qab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO anonomyze data use presidio library created by Microsoft\n",
        "!pip install langchain-experimental openai presidio-analyzer presidio-anonymizer spacy Faker faiss-cpu tiktoken\n",
        "!python —m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "hKgxorwJUwyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "BlTEQk9Cg5QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_file = '/content/Medical_Report_Final.pdf'\n",
        "pdf = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "# Count the number of pages present\n",
        "num_pages = len(pdf.pages)\n",
        "print(f\"Number of pages in the PDF: {num_pages}\")\n",
        "\n",
        "# Extract text from the first three pages\n",
        "text = \"\"\n",
        "for i in range(min(3, num_pages)):  # Loop through the first three pages or less if there are fewer pages\n",
        "    page_text = pdf.pages[i].extract_text()\n",
        "    text += page_text\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "id": "hqwOCArZgPRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_content=text\n",
        "print(document_content)"
      ],
      "metadata": {
        "id": "EItmYmCLVmhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import PatternRecognizer\n",
        "titles_recognizer = PatternRecognizer(supported_entity=\"TITLE\",\n",
        "                                      deny_list=[\"Mr.\",\"Mrs.\",\"Miss\"])\n",
        "import re\n",
        "from presidio_analyzer import PatternRecognizer\n",
        "\n",
        "from presidio_analyzer import PatternRecognizer, Pattern\n",
        "\n",
        "# Define a regex pattern to capture the entire string after \"No.\"\n",
        "address_pattern = r\"\\b(?:Qr|Plot|Flat|House|Building)\\sNo\\.\\s.*\\.\"\n",
        "\n",
        "# Create a PatternRecognizer for addresses\n",
        "address_recognizer = PatternRecognizer(\n",
        "    supported_entity=\"ADDRESS\",\n",
        "    patterns=[Pattern(name=\"custom_address_pattern\", regex=address_pattern, score=0.5)]\n",
        ")\n",
        "\n",
        "# Test address recognition using the updated recognizer\n",
        "address_entities = address_recognizer.analyze(text=\"Plot No. D/5, U.c.p Engineering School Colony.\", entities=\"ADDRESS\")\n",
        "print(address_entities)\n"
      ],
      "metadata": {
        "id": "35RLT-drms4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles_recognizer.analyze(text=\"Mr. Schmidt\", entities=\"TITLE\")\n",
        "address_recognizer.analyze(text=\"Qr No. D/5, U.c.p Engineering School Colony. TMEi\",entities=\"ADDRESS\")"
      ],
      "metadata": {
        "id": "JbAziGb5mxAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Shell conatains COde to Add Custom PII Parametrs.\n",
        "# This is for learning purpose to implement Address identification by Presidio Library, that's why it is kept commented\n",
        "# from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n",
        "\n",
        "# registry = RecognizerRegistry()\n",
        "# registry.load_predefined_recognizers()\n",
        "\n",
        "# # Add the recognizer to the existing list of recognizers\n",
        "# registry.add_recognizer(titles_recognizer)\n",
        "\n",
        "# # Set up analyzer with our updated recognizer registry\n",
        "# analyzer = AnalyzerEngine(registry=registry)\n",
        "\n",
        "# # Run with input text\n",
        "# text=\"His name is Mr. Jones\"\n",
        "# # results = analyzer.analyze(text=text, language=\"en\")\n",
        "# # print(results)"
      ],
      "metadata": {
        "id": "WSctf2Ppm1uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Shell conatains COde to Add Custom PII Parametrs.\n",
        "# This is for learning purpose to implement Address identification by Presidio Library, that's why it is kept commented\n",
        "\n",
        "# from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "# analyzer = AnalyzerEngine()\n",
        "\n",
        "# analyzer.registry.add_recognizer(titles_recognizer)\n",
        "\n",
        "# results = analyzer.analyze(text=text,language=\"en\")\n",
        "# print(results)"
      ],
      "metadata": {
        "id": "Nz32bWYQpIJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "documents =[Document(page_content=document_content)]"
      ],
      "metadata": {
        "id": "-Wv_8FgKXOpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We only have one document, so before we move on to creating a QA system, let's focus on its\n",
        "content to begin with.\n",
        "You may observe that the text contains many different PII values, some types occur repeatedly\n",
        "(names, phone numbers, emails), and some specific PIIs are repeated (John Doe)."
      ],
      "metadata": {
        "id": "6HQ9ROL1Xd-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Util function for coloring the PII markers\n",
        "# NOTE: It wilt not be visible on documentation page, only in the notebook\n",
        "import re\n",
        "def print_colored_pii(string):\n",
        "  colored_stding = re.sub(\n",
        "      r\"(<[^>]*>)\",lambda m:\"\\033[31m\" + m.group(1) +\"\\033[0m\",string)\n",
        "  print(colored_stding)"
      ],
      "metadata": {
        "id": "XWumc2ZzXb0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.data_anonymizer import PresidioReversibleAnonymizer\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities.engine import OperatorConfig\n",
        "from presidio_analyzer import PatternRecognizer\n",
        "\n",
        "\n",
        "anonymizer = PresidioReversibleAnonymizer(add_default_faker_operators=False,)\n",
        "\n",
        "print_colored_pii(anonymizer.anonymize(document_content))"
      ],
      "metadata": {
        "id": "TTdFGT12YNct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(anonymizer.deanonymizer_mapping)"
      ],
      "metadata": {
        "id": "qqsbMARyY1eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import Pattern, PatternRecognizer, RecognizerRegistry\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities.engine import OperatorConfig\n",
        "\n",
        "# Define a regex pattern to capture the entire string after \"No.\"\n",
        "address_pattern = r'(?:\\b(?:Qr|Plot|Flat)\\sNo\\.\\s.*\\.|\\b[\\w\\s,-]+,\\s*[\\w\\s,-]+,\\s*[\\w\\s,-]+\\b)'\n",
        "\n",
        "# Create a PatternRecognizer for addresses\n",
        "address_recognizer = PatternRecognizer(\n",
        "    supported_entity=\"ADDRESS\",\n",
        "    patterns=[Pattern(name=\"custom_address_pattern\", regex=address_pattern, score=0.5)]\n",
        ")\n",
        "\n",
        "\n",
        "# Define the regex pattern in a Presidio 'Pattern' object\n",
        "polish_id_pattern = Pattern(\n",
        "    name=\"polish_id_pattern\",\n",
        "    regex=r\"[A-Z]{3}\\d{6}\",  # Ensure to use raw string (r\"\") for regex patterns\n",
        "    score=1,\n",
        ")\n",
        "\n",
        "time_pattern = Pattern(\n",
        "    name=\"time_pattern\",\n",
        "    regex=r\"(1[0-2]|0?[1-9]):[0-5][0-9] (AM|PM)\",\n",
        "    score=1,\n",
        ")\n",
        "\n",
        "# Define the recognizer with one or more patterns\n",
        "polish_id_recognizer = PatternRecognizer(\n",
        "    supported_entity=\"POLISH_ID\",\n",
        "    patterns=[polish_id_pattern]\n",
        ")\n",
        "\n",
        "time_recognizer = PatternRecognizer(\n",
        "    supported_entity=\"TIME\",\n",
        "    patterns=[time_pattern]\n",
        ")\n",
        "\n",
        "# Add recognizers to the registry\n",
        "anonymizer.add_recognizer(polish_id_recognizer)\n",
        "anonymizer.add_recognizer(time_recognizer)\n",
        "anonymizer.add_recognizer(address_recognizer)\n",
        "# Initialize the anonymizer engine\n",
        "\n",
        "# Assuming document_content is the content you want to anonymize\n",
        "# Anonymize the content using the Presidio anonymizer\n",
        "anonymized_content = anonymizer.anonymize(text=document_content)\n",
        "\n",
        "# You can then print the anonymized content\n",
        "print(anonymized_content)\n"
      ],
      "metadata": {
        "id": "pm8eKETVZ62l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are adding annonomizer"
      ],
      "metadata": {
        "id": "UGTZQqAHbkLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anonymizer.add_recognizer(polish_id_recognizer)\n",
        "anonymizer.add_recognizer(time_recognizer)\n",
        "anonymizer.add_recognizer(address_recognizer)"
      ],
      "metadata": {
        "id": "hCvB_-RsbFPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that our anonymization instance remembers previously detected and anonymized values,\n",
        "including those that were not detected correctly (e.g., •9:30 AM• taken as DATE _ TIME ). So\n",
        "it's worth removing this value, or resetting the entire mapping now that our recognizers have\n",
        "been updated:"
      ],
      "metadata": {
        "id": "7EQDhVZQb55c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anonymizer.reset_deanonymizer_mapping()"
      ],
      "metadata": {
        "id": "5mrTCyQvb3K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's anonymise the text and see the results"
      ],
      "metadata": {
        "id": "R0kRrxN4cD3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_colored_pii(anonymizer.anonymize(document_content))"
      ],
      "metadata": {
        "id": "PxdguufVcC3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(anonymizer.deanonymizer_mapping)"
      ],
      "metadata": {
        "id": "YBfvjRwecNnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymizer= PresidioReversibleAnonymizer(\n",
        "    add_default_faker_operators=True,\n",
        "    faker_seed=42,\n",
        ")\n",
        "\n",
        "anonymizer.add_recognizer(polish_id_recognizer)\n",
        "anonymizer.add_recognizer(address_recognizer)\n",
        "anonymizer.add_recognizer(time_recognizer)\n",
        "print_colored_pii(anonymizer.anonymize(document_content))"
      ],
      "metadata": {
        "id": "aUWPy_qQee87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "def fake_polish_id(_=None):\n",
        "  return fake.bothify(text=\"???######\").upper()\n",
        "\n",
        "fake_polish_id()"
      ],
      "metadata": {
        "id": "J0svo3Kpe_fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fake_time(_=None):\n",
        "  return fake.time(pattern=\"%I:%M %p\")\n",
        "\n",
        "fake_time()"
      ],
      "metadata": {
        "id": "nRbvocxvfxpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "new_operators = {\n",
        "    \"POLISH_ID\": OperatorConfig(\"custom\", {\"lambda\" : fake_polish_id}),\n",
        "    \"TIME\": OperatorConfig(\"custom\", {\"lambda\": fake_time}),\n",
        "}\n",
        "anonymizer.add_operators(new_operators)"
      ],
      "metadata": {
        "id": "mzXoYD9mgHD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymizer.reset_deanonymizer_mapping()\n",
        "print_colored_pii(anonymizer.anonymize(document_content))"
      ],
      "metadata": {
        "id": "186x2lgEgj1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG extends the already powerful capabilities of LLMs to specific domains or an organization's internal knowledge base, all without the need to retrain the model.\n",
        "\n",
        "Retrieval augmented generation (RAG) is a natural language processing (NLP) technique that combines the strengths of both retrieval- and generative-based artificial intelligence (AI) models."
      ],
      "metadata": {
        "id": "kvmboTkfhLwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I. Initialize anonymizer\n",
        "anonymizer = PresidioReversibleAnonymizer(\n",
        "# Faker seed is used here to make sure the same fake data is generated for the test purposes\n",
        "# In production, it is recommended to remove the faker_seed parameter (it will default to None)\n",
        "  faker_seed=42,)\n",
        "anonymizer.add_recognizer(polish_id_recognizer)\n",
        "anonymizer.add_recognizer(address_recognizer)\n",
        "anonymizer.add_recognizer(time_recognizer)\n",
        "anonymizer. add_operators(new_operators)"
      ],
      "metadata": {
        "id": "QFSBc5iAhLU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Set your OpenAI API key here or retrieve it from environment variables\n",
        "openai_api_key = \"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\"\n",
        "\n",
        "# Load the data: Assuming 'documents' are already loaded\n",
        "# Anonymize the data before indexing\n",
        "for doc in documents:\n",
        "    doc.page_content = anonymizer.anonymize(doc.page_content)\n",
        "\n",
        "# Split the documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# Initialize OpenAI embeddings by passing the API key\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "# Index the chunks using OpenAI embeddings (assuming the data is already anonymized)\n",
        "docsearch = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = docsearch.as_retriever()\n"
      ],
      "metadata": {
        "id": "NWCY4ZOygvbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "from langchain.chat_models.openai import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnableMap\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "\n",
        "\n",
        "# 6. Create anonymizer chain\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "Question: {anonymized_question}\n",
        "Note: Try to recognize patient's Name and treat it separately, The PDF might contain two names which it does\n",
        "but your task is to treat both names differently and treat them separately. Dont just concatenate two names.\n",
        "For Example If you encounter John DOe Adam Doe then John DOe is a separate name and Adam Doe is a different name.\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model=ChatOpenAI(openai_api_key=openai_api_key,temperature=0.5)\n",
        "\n",
        "_inputs = RunnableMap(\n",
        "    question=RunnablePassthrough(),\n",
        "    # It is important to remember about question anonymization\n",
        "    anonymized_question=RunnableLambda(anonymizer.anonymize),\n",
        ")\n",
        "\n",
        "anonymizer_chain = (\n",
        "    _inputs\n",
        "    | {\n",
        "        \"context\": itemgetter(\"anonymized_question\") | retriever,\n",
        "        \"anonymized_question\": itemgetter(\"anonymized_question\"),\n",
        "    }\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "0FYyKRU_jCO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anonymizer_chain.invoke(\n",
        "  \"Can You Please Summarize the medical Report ALso Mention separately the name of the patient?\"\n",
        ")"
      ],
      "metadata": {
        "id": "PcA4XX_xqYYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Add deanonymization step to the chain\n",
        "chain_with_deanonymization = anonymizer_chain | RunnableLambda (anonymizer.deanonymize)\n",
        "print(chain_with_deanonymization.invoke(\"Can You Please Summarize the medical Report ALso Mention separately the name of the patient?\"))"
      ],
      "metadata": {
        "id": "do6Uh0z7t7yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_report=chain_with_deanonymization.invoke(\"Can You Please Summarize the medical Report ALso Mention separately the name of the patient?\")\n",
        "print(summarized_report)"
      ],
      "metadata": {
        "id": "USQEuc3i4exe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain_with_deanonymization.invoke(\"WHose phone number is it : (97779) 80507, Return if you find any match?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPqtTuLw4pDn",
        "outputId": "665df233-cb3b-40ad-82ed-fcc18e45d5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the given context, the phone number (97779) 80507 is associated with the individual named India.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open( \"Summarized_Medical_Report.txt\", \"w\",encoding='utf-8') as f:\n",
        "  f.write(\"Message Generated by LLM\"+summarized_report)"
      ],
      "metadata": {
        "id": "KL8oNq-GH09U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n"
      ],
      "metadata": {
        "id": "X21-0WX4FGBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reportlab.pdfgen import canvas\n",
        "\n",
        "def create_pdf_with_text(text, output_filename):\n",
        "    # Create a canvas object to draw on\n",
        "    c = canvas.Canvas(output_filename)\n",
        "\n",
        "    # Set font and font size for the text\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "\n",
        "    # Insert text onto the page\n",
        "    c.drawString(100, 700, text)  # Adjust the coordinates (x, y) as needed\n",
        "\n",
        "    # Save the PDF to a file\n",
        "    c.save()\n",
        "    print(f\"PDF with text '{text}' created successfully as '{output_filename}'\")\n",
        "\n",
        "# Example usage:\n",
        "text_to_add = summarized_report\n",
        "output_file_name = \"Medical_Summary_Report.pdf\"\n",
        "\n",
        "create_pdf_with_text(text_to_add, output_file_name)\n"
      ],
      "metadata": {
        "id": "3AZITjIx4z6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}